# ğŸ™ï¸ Deepfake Audio Detection using CNN & Spectrograms

![Python](https://img.shields.io/badge/Python-3.9-blue?logo=python)
![Torch](https://img.shields.io/badge/PyTorch-Used-red?logo=pytorch)
![Librosa](https://img.shields.io/badge/Librosa-Audio-green?logo=librosa)
![Status](https://img.shields.io/badge/Status-In_Progress-yellow)

---

## ğŸ“Œ Overview

This project focuses on detecting **deepfake audio** using a **Convolutional Neural Network (CNN)** trained on **mel spectrograms** extracted from `.wav` files. With the rise of synthetic voices and AI-generated speech, this model helps identify fake audio recordings with high accuracy.

---

## ğŸ§  Objective

ğŸ¯ Build a deep learning model to:
- Differentiate between **real** and **fake** audio samples
- Use **mel spectrograms** for feature extraction
- Apply **CNN** to classify audio effectively
- Evaluate performance on separate train, validation, and test sets

---

## ğŸ—‚ï¸ Dataset Structure

